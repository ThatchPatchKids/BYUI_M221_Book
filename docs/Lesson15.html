<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Lesson 15: Review for Exam 2</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Math 221</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Unit 1
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Lesson 1: Course Intro &amp; Probability</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="Lesson01_Campus.html">Campus Student Version</a>
        </li>
        <li>
          <a href="Lesson01.html">Online Student Version</a>
        </li>
        <li>
          <a href="Lesson01_WWB.html">World Wide Block Student Version</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="Lesson02.html">Lesson 2: The Statistical Process</a>
    </li>
    <li>
      <a href="Lesson03.html">Lesson 3: Describing Quantitative Data (Shape &amp; Center)</a>
    </li>
    <li>
      <a href="Lesson04.html">Lesson 4: Describing Quantitative Data (Spread)</a>
    </li>
    <li>
      <a href="Lesson05.html">Lesson 5: Normal Distributions</a>
    </li>
    <li>
      <a href="Lesson06.html">Lesson 6: The Central Limit Theorem</a>
    </li>
    <li>
      <a href="Lesson07.html">Lesson 7: Calculating Probabilities involving the Sample Mean</a>
    </li>
    <li>
      <a href="Lesson08.html">Lesson 8: Unit 1 Review</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Unit 2
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lesson09.html">Lesson 9: Hypothesis Test for One Mean (Sigma Known)</a>
    </li>
    <li>
      <a href="Lesson10.html">Lesson 10: Confidence Interval for One Mean (Sigma Known)</a>
    </li>
    <li>
      <a href="Lesson11.html">Lesson 11: Inference for One Mean (Sigma Unknown)</a>
    </li>
    <li>
      <a href="Lesson12.html">Lesson 12: Inference for the Mean of Differences (Two Dependent Samples)</a>
    </li>
    <li>
      <a href="Lesson13.html">Lesson 13: Inference for the Difference of Means (Two Independent Samples)</a>
    </li>
    <li>
      <a href="Lesson14.html">Lesson 14: Inference using ANOVA (Several Independent Samples)</a>
    </li>
    <li>
      <a href="Lesson15.html">Lesson 15: Unit 2 Review</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Unit 3
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lesson16.html">Lesson 16: Describing Categorical Data</a>
    </li>
    <li>
      <a href="Lesson17.html">Lesson 17: Inference for One Proportion</a>
    </li>
    <li>
      <a href="Lesson18.html">Lesson 18: Inference for Two Proportions</a>
    </li>
    <li>
      <a href="Lesson19.html">Lesson 19: Inference for Independence of Categorical Data</a>
    </li>
    <li>
      <a href="Lesson20.html">Lesson 20: Unit 3 Review</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Unit 4
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Lesson21.html">Lesson 21: Describing Bivariate Data</a>
    </li>
    <li>
      <a href="Lesson22.html">Lesson 22: Simple Linear Regression</a>
    </li>
    <li>
      <a href="Lesson23.html">Lesson 23: Inference for Bivariate Data</a>
    </li>
    <li>
      <a href="Lesson24.html">Lesson 24: Unit 4 Review</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="./Data/Math221StatisticsToolbox.xlsx">Toolbox</a>
</li>
<li>
  <a href="Data.html">Data</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Lesson 15: Review for Exam 2</h1>

</div>


<script type="text/javascript">
 function showhide(id) {
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
 }
</script>
<p>Unit 2 introduced you to hypothesis testing and confidence intervals
as well as five inferential methods in statistics. Review the Lesson
Outcomes and Lesson Summaries from each lesson to prepare for the Unit 2
Exam. For any outcomes where you need further review, return to the
corresponding lesson and study those topics in more depth.</p>
<div id="lesson-9" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 9</h2>
<div id="outcomes" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when a one mean (sigma known) hypothesis test is
appropriate</li>
<li>Define a P-value (one-sided and two-sided)</li>
<li>Perform a hypothesis test for a single mean with σ known using the
following steps:
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses</li>
<li>Calculate the test-statistic by hand</li>
<li>Determine the P-value using the normal distribution</li>
<li>Assess statistical significance in order to state the appropriate
conclusion for the hypothesis test</li>
<li>Check the requirements for the hypothesis test</li>
</ol></li>
<li>Interpret Type I and II errors in the context of a hypothesis
test</li>
<li>Explain the meaning of the level of significance (<span
class="math inline">\(\alpha\)</span>)</li>
</ol>
</div>
<div id="summary" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ol style="list-style-type: decimal">
<li><p>A one mean (sigma known) hypothesis test is appropriate for
testing a hypothesized value of the mean of a population for
quantitative data where <span class="math inline">\(\sigma\)</span>, the
population standard deviation, can reasonably be assumed to be known
exactly.</p></li>
<li><p>A <span class="math inline">\(P\)</span>-value gives the
probability of observing a test statistic at least as extreme as the one
observed, assuming the null hypothesis is true.</p></li>
<li><p>The steps to perform a hypothesis test for one mean when sigma is
known are:</p>
<ol style="list-style-type: lower-alpha">
<li><p>First, state the hypotheses. The <strong>null hypothesis (<span
class="math inline">\(H_0\)</span>)</strong> is the foundational
assumption about a population and represents the status quo that we
assume to be true. It is a statement of equality (<span
class="math inline">\(=\)</span>). The <strong>alternative hypothesis
(<span class="math inline">\(H_a\)</span>)</strong> is a different
assumption about a population and is a statement of inequality (<span
class="math inline">\(&lt;\)</span>, <span
class="math inline">\(&gt;\)</span>, or <span
class="math inline">\(\ne\)</span>). The alternative hypothesis is
believed to be true only in the case that sufficient evidence is
presented.</p></li>
<li><p>The test statistic for the one mean (sigma known) hypothesis test
is given by the equation <span class="math display">\[
  z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}
\]</span></p></li>
<li><p>The <span class="math inline">\(P\)</span>-value is calculated by
finding the area under the normal distribution curve that is more
extreme (farther away from the mean) than the z-score. The alternative
hypothesis tells us whether we look at both tails or only one. The
possible scenarios are depicted below.</p>
<div style="padding-right:3%;">
<table id="fancytable">
<tr>
<th>
Left-tailed <br/> <span class="math inline">\(H_a: \mu &lt; 0\)</span>
</th>
<th>
Two-tailed <br/> <span class="math inline">\(H_a: \mu \neq 0\)</span>
</th>
<th>
Right-tailed<br/> <span class="math inline">\(H_a: \mu &gt; 0\)</span>
</th>
</tr>
<tr>
<td>
<img src="Images/pvalue_left_tail.png" width="200">
</td>
<td>
<img src="Images/pvalue_two_tail.png" width="200"><br />

</td>
<td>
<img src="Images/pvalue_right_tail.png" width="200"><br />

</td>
</tr>
</table>
<table id="fancytable">
<tr>
<th>
Left-tailed <br/> <span class="math inline">\(H_a: \mu &lt; 0\)</span>
</th>
<th style="width:33%">
</th>
<th>
Right-tailed<br/> <span class="math inline">\(H_a: \mu &gt; 0\)</span>
</th>
</tr>
<tr>
<td>
<img src="Images/pvalue_left_tail_posz.png" width="200">
</td>
<td>
</td>
<td>
<img src="Images/pvalue_right_tail_negz.png" width="200"><br />

</td>
</tr>
</table>
</div></li>
<li><p>The <strong>level of significance (<span
class="math inline">\(\alpha\)</span>)</strong> controls the probability
of committing a Type I Error. It is the standard for determining whether
or not the null hypothesis should be rejected. Typical values for <span
class="math inline">\(\alpha\)</span> are <span
class="math inline">\(0.05\)</span>, <span
class="math inline">\(0.10\)</span>, and <span
class="math inline">\(0.01\)</span>. If the <span
class="math inline">\(P\)</span>-value is less than <span
class="math inline">\(\alpha\)</span> we reject the null and have
sufficient evidence to believe the alternative hypothesis is true. If
the <span class="math inline">\(P\)</span>-value is greater than <span
class="math inline">\(\alpha\)</span> we fail to reject the null and
have insufficient evidence to believe the alternative hypothesis is
true.</p></li>
<li><p>The results of a one mean (sigma known) test are meaningful when
(1) the sample of data can be considered to be representative of the
population and (2) the sampling distribution of the sample mean can be
considered to be normal. Recall from <a href="Lesson06.html">Lesson
6</a> that the sampling distribution of the sample mean can be
considered normal whenever the population data is normal or when the
sample size is sufficiently large, i.e., <span
class="math inline">\(n\ge 30\)</span>.</p></li>
</ol></li>
<li><p>A <strong>Type I error</strong> is committed when we reject a
null hypothesis that is, in reality, true. A <strong>Type II
error</strong> is committed when we fail to reject a null hypothesis
that is, in reality, false.</p></li>
<li><p>The level of significance, <span
class="math inline">\(\alpha\)</span>, gives the probability of
committing a Type I error. The probability of a Type II Error is called
<span class="math inline">\(\beta\)</span>, but <span
class="math inline">\(\beta\)</span> is not discussed in this course.
However, the probabilities of a Type I Error (<span
class="math inline">\(\alpha\)</span>) and a Type II Error (<span
class="math inline">\(\beta\)</span>) are inversely related, in other
words, as one increases the other is decreased.</p></li>
</ol>
</div>
</div>
</div>
<div id="lesson-10" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 10</h2>
<div id="outcomes-1" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when a one mean (sigma known) confidence interval is
appropriate</li>
<li>Calculate the sample size required to achieve a specified margin of
error and level of confidence</li>
<li>Explain the meaning of a level of confidence</li>
<li>Create a confidence interval for a single mean with σ known using
the following steps:
<ol style="list-style-type: lower-alpha">
<li>Find the point estimate</li>
<li>Calculate the margin of error for the given level of confidence</li>
<li>Calculate a confidence interval from the point estimate and the
margin of error</li>
<li>Interpret the confidence interval</li>
<li>Check the requirements for the confidence interval</li>
</ol></li>
<li>Explain how the margin of error is affected by the sample size and
level of confidence</li>
</ol>
</div>
<div id="summary-1" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ol style="list-style-type: decimal">
<li><p>A confidence interval for the true mean <span
class="math inline">\(\mu\)</span> can be created whenever there is one
sample of quantitative data and the population standard deviation <span
class="math inline">\(\sigma\)</span> is known.</p></li>
<li><p>To calculate the sample size required to achieve a specified
margin of error, given a chosen level of confidence, we use the
equation<br />
<span class="math display">\[
n = \left(\frac{z^*\sigma}{m}\right)^2 \quad
\]</span> where <span class="math inline">\(m\)</span> is the desired
margin of error (measured in the same units of measurement as the data),
and <span class="math inline">\(z^*\)</span> (see the next bullet point
for details about <span class="math inline">\(z^*\)</span>) is the
critical value for the given level of confidence.</p></li>
<li><p>The <em>confidence level</em> is a choice that we make of either
90%, 95%, or 99% that determines how often we would expect our
confidence intervals to capture the true population parameter, <span
class="math inline">\(\mu\)</span>. The confidence level is a central
region on the normal applet equal to <span
class="math inline">\(1-\alpha\)</span>. This central region represents
the specified proportion (0.9, 0.95, or 0.99) of the distribution all
possible sample means that are contained within a specified distance of
<span class="math inline">\(\mu\)</span>. This distance from <span
class="math inline">\(\mu\)</span> is called <span
class="math inline">\(z^*\)</span>, or <em>the critical value</em>. This
<span class="math inline">\(z^*\)</span> is the z-score that bounds the
central area corresponding to our chosen level of confidence on the
normal distribution.</p></li>
</ol>
<table id="fancytable">
<tr>
<th>
90% Confidence Level <br/> <span class="math inline">\(z^* =
1.645\)</span>
</th>
<th>
95% Confidence Level<br/> <span class="math inline">\(z^* =
1.960\)</span>
</th>
<th>
99% Confidence Level<br/> <span class="math inline">\(z^* =
2.576\)</span>
</th>
</tr>
<tr>
<td>
<img src="Images/criticalvalue_90.png" width="200">
</td>
<td>
<img src="Images/criticalvalue_95.png" width="200">
</td>
<td>
<img src="Images/criticalvalue_99.png" width="200">
</td>
</tr>
</table>
<p><br/></p>
<ol start="4" style="list-style-type: decimal">
<li>To create a confidence interval for a single mean with <span
class="math inline">\(\sigma\)</span> known we use the equation: <span
class="math display">\[
  \underbrace{\bar{x}}_\stackrel{\text{Point}}{\text{Estimate}} \pm
\underbrace{z^* \frac{\sigma}{\sqrt{n}}}_\text{Margin of Error}
\]</span>
<ol style="list-style-type: lower-alpha">
<li><p>To use this equation, we first calculate the point estimate of
<span class="math inline">\(\mu\)</span>, which is <span
class="math inline">\(\bar{x}\)</span>, the sample mean.</p></li>
<li><p>We then calculate the margin of error using the <span
class="math inline">\(z^*\)</span> corresponding to our chosen level of
significance (usually 95%, in which case <span class="math inline">\(z^*
= 1.960\)</span>), the known value of <span
class="math inline">\(\sigma\)</span>, and the square root of the sample
size <span class="math inline">\(n\)</span>.</p></li>
<li><p>The lower-bound of the confidence interval is obtained by <span
class="math inline">\(\bar{x} - z^*\sigma/\sqrt{n}\)</span> and the
upper-bound of the confidence interval is obtained by <span
class="math inline">\(\bar{x} + z^*\sigma/\sqrt{n}\)</span>.</p></li>
<li><p>We then claim we are 95% confident that the true mean <span
class="math inline">\(\mu\)</span> lives inside the region specified
between the lower-bound and the upper-bound on the number line. Using
this approach, we expect to be correct in our conclusions 95% of the
time. But keep in mind there is no “chance” or “probability” that we are
correct as our resulting interval has either captured the true mean or
it has not.</p></li>
<li><p>To ensure the confidence interval is meaningful and appropriate
for a set of data, we need to ensure that (1) our sample was
representative of the population, and (2) the distribution of <span
class="math inline">\(\bar{x}\)</span> can be considered normal by
either the virtue of the data being normal itself, or the sample size
being sufficiently large to invoke the Central Limit Theorem.</p></li>
</ol></li>
<li>The <strong>margin of error</strong> gives an estimate of the
variability of responses. As shown by its equation, <span
class="math inline">\(\displaystyle{m=z^*\frac{\sigma}{\sqrt{n}}}\)</span>,
there are two values directly under our control (<span
class="math inline">\(z^*\)</span> and <span
class="math inline">\(n\)</span>) which impact the size of the margin of
error. The larger the value of <span class="math inline">\(z^*\)</span>,
the greater our confidence level, and the larger the margin of error
becomes. The larger the sample size <span
class="math inline">\(n\)</span>, the smaller the margin of error will
become. A smaller margin of error gives greater insight about the true
value of <span class="math inline">\(\mu\)</span>.</li>
</ol>
<p><br/></p>
</div>
</div>
</div>
<div id="lesson-11" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 11</h2>
<div id="outcomes-2" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when a one mean (sigma unknown) inferential procedure is
appropriate</li>
<li>Create numerical and graphical summaries of the data</li>
<li>Perform a hypothesis test for one mean (sigma unknown) using the
following steps:
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses</li>
<li>Calculate the test-statistic, degrees of freedom and P-value using
software</li>
<li>Assess statistical significance in order to state the appropriate
conclusion for the hypothesis test</li>
<li>Check the requirements for the hypothesis test</li>
</ol></li>
<li>Create a confidence interval for one mean (sigma unknown) using the
following steps:
<ol style="list-style-type: lower-alpha">
<li>Calculate a confidence interval for a given level of confidence
using software</li>
<li>Interpret the confidence interval</li>
<li>Check the requirements of the confidence interval</li>
</ol></li>
<li>State the properties of the Student’s t-distribution</li>
</ol>
</div>
<div id="summary-2" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ol style="list-style-type: decimal">
<li><p>In practice we rarely know the true standard deviation <span
class="math inline">\(\sigma\)</span>. Thus, when we have one sample of
quantitative data without knowledge of <span
class="math inline">\(\sigma\)</span> we will use a one sample t
inferential procedure for <span
class="math inline">\(\mu\)</span>.</p></li>
<li><p>Appropriate ways of <em>Describing the Data</em> for one sample
of quantitative data where <span class="math inline">\(\sigma\)</span>
is unknown include making either a histogram or boxplot of the sample
data, along with calculating the sample mean <span
class="math inline">\(\bar{x}\)</span>, the sample standard deviation
<span class="math inline">\(s\)</span>, and the sample size <span
class="math inline">\(n\)</span>.</p></li>
<li><p>To perform a hypothesis test for one mean (sigma unknown) use the
following steps:</p>
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypothesis in the form of <span
class="math inline">\(H_0: \mu = \text{some number}\)</span> and <span
class="math inline">\(H_a: \mu \ne \text{some number}\)</span>. A
one-sided alternative (<span class="math inline">\(&lt;\)</span> or
<span class="math inline">\(&gt;\)</span>) can be used in place of the
two-sided <span class="math inline">\(\ne\)</span> when
appropriate.</li>
<li>The <strong>student’s t-distribution</strong> gives us a new test
statistic, <span class="math inline">\(t\)</span>, that measures how far
the sample mean has landed from our hypothesized value of <span
class="math inline">\(\mu\)</span> using the sample standard deviation
(<span class="math inline">\(s\)</span>) and the sample size <span
class="math inline">\(n\)</span> by the equation <span
class="math display">\[
t = \frac {\bar x - \mu} {s / \sqrt{n}}
\]</span> The degrees of freedom corresponding to this test statistic
are <span class="math inline">\(df = n-1\)</span>, and the <span
class="math inline">\(P\)</span>-value is obtained by shading the
appropriate tails (as specified in the alternative hypothesis) of the
<span class="math inline">\(t\)</span>-distribution with <span
class="math inline">\(n-1\)</span> degrees of freedom.</li>
<li>The results of the test are based on how the <span
class="math inline">\(P\)</span>-value compares to the significance
level <span class="math inline">\(\alpha\)</span>. As before, if the
<span class="math inline">\(P\)</span>-value is less than <span
class="math inline">\(\alpha\)</span>, the null hypothesis is rejected
and there is sufficient evidence to believe the alternative hypothesis
is true. If the <span class="math inline">\(P\)</span>-value is greater
than <span class="math inline">\(\alpha\)</span>, the null hypothesis is
not rejected and there is insufficient evidence to believe the
alternative hypothesis is true.</li>
<li>In order for the results of the one sample t test to be considered
valid, it must be the case that (1) the sample is representative of the
population and (2) the distribution of <span
class="math inline">\(\bar{x}\)</span> can be considered to be normally
distributed.</li>
</ol></li>
<li><p>To create a confidence interval for one mean (sigma unknown)
we</p>
<ol style="list-style-type: lower-alpha">
<li>Use software to evaluate the following expression in order to obtain
the lower-bound and upper-bound of the confidence interval. <span
class="math display">\[
  \underbrace{\bar{x}}_\stackrel{\text{Point}}{\text{Estimate}} \pm
\underbrace{t^* \frac{s}{\sqrt{n}}}_\text{Margin of Error}
\]</span></li>
<li>Interpret the confidence interval by stating that we are 95% (or 90%
or 99%) confident that the true mean <span
class="math inline">\(\mu\)</span> is contained in the confidence
interval. We expect to be correct 95% (or 90% or 99%) of the time when
using such a confidence interval to make claims about the true value of
<span class="math inline">\(\mu\)</span>.</li>
<li>In order for the confidence interval to be considered valid, it must
be the case that (1) the sample is representative of the population and
(2) the distribution of <span class="math inline">\(\bar{x}\)</span> can
be considered to be normally distributed.</li>
</ol></li>
<li><p>The <span class="math inline">\(t\)</span>-distribution is
similar to a normal distribution in that it is bell-shaped and
symmetrical, but the exact shape of the <span
class="math inline">\(t\)</span>-distribution depends on the
<strong>degrees of freedom (<span class="math inline">\(df =
n-1\)</span>)</strong>. As the degrees of freedom grow larger, the <span
class="math inline">\(t\)</span>-distribution becomes more and more
normal in shape.</p></li>
</ol>
<p><br/></p>
</div>
</div>
</div>
<div id="lesson-12" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 12</h2>
<div id="outcomes-3" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when a mean of differences (two dependent samples)
inferential procedure is appropriate</li>
<li>Create numerical and graphical summaries of the data</li>
<li>Perform a hypothesis test for the mean of differences (two dependent
samples) using the following steps:
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses</li>
<li>Calculate the test-statistic, degrees of freedom and P-value of the
test using software</li>
<li>Assess statistical significance in order to state the appropriate
conclusion for the hypothesis test</li>
<li>Check the requirements for the hypothesis test</li>
</ol></li>
<li>Create a confidence interval for the mean of differences (two
dependent samples) using the following steps:
<ol style="list-style-type: lower-alpha">
<li>Calculate a confidence interval using software</li>
<li>Interpret the confidence interval</li>
<li>Check the requirements of the confidence interval</li>
</ol></li>
</ol>
</div>
<div id="summary-3" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ol style="list-style-type: decimal">
<li><p>The key characteristic of <strong>dependent samples</strong> (or
<strong>matched pairs</strong>) is that knowing which subjects will be
in group 1 determines which subjects will be in group 2. Examples
include pre and post testing situations where the same subjects are
measured twice, or matched pair situations with married couples,
identical twins, or other situations where subjects from one group are
carefully matched with subjects from another group.</p></li>
<li><p>Appropriate ways of <em>Describing the Data</em> for dependent
samples is with either a histogram or boxplot of the computed
differences (of each pair of values), and computing the sample size
<span class="math inline">\(n\)</span>, the sample mean of the
differences <span class="math inline">\(\bar{d}\)</span>, and the sample
standard deviation of the differences <span
class="math inline">\(s_d\)</span>.</p></li>
<li><p>To perform a hypothesis test for the true mean of the differences
(two dependent samples) use the following steps:</p>
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses in the form <span
class="math inline">\(H_0: \mu_d = 0\)</span> and <span
class="math inline">\(H_a: \mu_d \neq 0\)</span>. Use the one-sided
alternatives of <span class="math inline">\(\mu_d &lt; 0\)</span> or
<span class="math inline">\(\mu_d &gt; 0\)</span> when appropriate.</li>
<li>Before describing the data or making inference, we first compute the
differences <span class="math inline">\(d\)</span> using the equation
<strong>differences = Data 1 values - Data 2 values</strong>. Then the
test statistic is found using the equation <span class="math display">\[
   t = \frac{\bar{d} - \mu_d}{\frac{s_d}{\sqrt{n}}}
\]</span> The degrees of freedom of this test statistic are <span
class="math inline">\(df=n-1\)</span>. The <span
class="math inline">\(P\)</span>-value is obtained by shading the
appropriate tails of the <span
class="math inline">\(t\)</span>-distribution with <span
class="math inline">\(n-1\)</span> degrees of freedom. The Math 221
Statistics Toolbox will provide each of these values.</li>
<li>The <span class="math inline">\(P\)</span>-value is compared to the
significance level in the usual way to determine if the null hypothesis
should be rejected (<span class="math inline">\(P\)</span>-value <span
class="math inline">\(&lt; \alpha\)</span>) and sufficient evidence
obtained to believe the alternative hypothesis is true.</li>
<li>The results of the hypothesis test are considered valid if (1) the
sample differences are representative of the population and (2) the mean
of the sample differences <span class="math inline">\(\bar{d}\)</span>
can be considered to be normal. (This last assumption is true if the
differences themselves appear to be normal, or if the sample size is
large enough to invoke the Central Limit Theorem.)</li>
</ol></li>
<li><p>To create a confidence interval for the true mean of the
differences (two dependent samples) use the following steps:</p>
<ol style="list-style-type: lower-alpha">
<li>Use the Math 221 Statistics Toolbox to compute the lower and upper
bounds of the confidence interval with the equation <span
class="math display">\[
  \underbrace{\bar{d}}_\stackrel{\text{Point}}{\text{Estimate}} \pm
\underbrace{t^* \frac{s_d}{\sqrt{n}}}_\text{Margin of Error}
\]</span></li>
<li>We are then 95% confident that the true mean of the differences is
some value within the resulting interval. If the confidence interval
contains zero, then it is possible that <span
class="math inline">\(\mu_d = 0\)</span> and we claim there is no
overall mean difference, i.e., no change on average in the subjects. If
both the lower-bound and the upper-bound are positive, then we are
confident the <strong>Data~1</strong> group of values is tending to be
larger than the <strong>Data~2</strong> values by anywhere from the
lower-bound to the upper-bound in value. Conversely, if both bounds are
negative, we are confident that the <strong>Data~1</strong> group of
values is tending to be smaller than the <strong>Data~2</strong> values
by anywhere from the upper-bound to the lower-bound in value.</li>
<li>The confidence interval is considered valid so long as (1) the
sample differences are representative of the population and (2) the mean
of the sample differences <span class="math inline">\(\bar{d}\)</span>
can be considered to be normal. (This last assumption is true if the
differences themselves appear to be normal, or if the sample size is
large enough to invoke the Central Limit Theorem.)</li>
</ol></li>
</ol>
<p><br></p>
</div>
</div>
</div>
<div id="lesson-13" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 13</h2>
<div id="outcomes-4" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when the difference of means (two independent samples)
inferential procedure is appropriate</li>
<li>Create numerical and graphical summaries of the data</li>
<li>Perform a hypothesis test for the difference of means (two
independent samples) using the following steps:
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses</li>
<li>Calculate the test-statistic, degrees of freedom and P-value of the
test using software</li>
<li>Assess statistical significance in order to state the appropriate
conclusion for the hypothesis test</li>
<li>Check the requirements for the hypothesis test</li>
</ol></li>
<li>Create a confidence interval for the difference of means (two
independent samples) using the following steps:
<ol style="list-style-type: lower-alpha">
<li>Calculate a confidence interval using software</li>
<li>Interpret the confidence interval</li>
<li>Check the requirements of the confidence interval</li>
</ol></li>
</ol>
</div>
<div id="summary-4" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ul>
<li><p>In contrast to dependent samples, two samples are independent if
knowing which subjects are in group 1 tells you nothing about which
subjects will be in group 2. With <strong>independent samples</strong>,
there is no pairing between the groups.</p></li>
<li><p>When conducting inference using independent samples we use <span
class="math inline">\(\bar x_1\)</span>, <span
class="math inline">\(s_1\)</span>, and <span
class="math inline">\(n_1\)</span> for the mean, standard deviation, and
sample size, respectively, of group 1. We use the symbols <span
class="math inline">\(\bar x_2\)</span>, <span
class="math inline">\(s_2\)</span>, and <span
class="math inline">\(n_2\)</span> for group 2.</p></li>
<li><p>When working with independent samples it is important to
graphically illustrate each sample separately. Combining the groups to
create a single graph is not appropriate.</p></li>
<li><p>When conducting hypothesis tests using independent samples, the
null hypothesis is always <span
class="math inline">\(\mu_1=\mu_2\)</span>, indicating that there is no
difference between the two populations. The alternative hypothesis can
be left-tailed (<span class="math inline">\(&lt;\)</span>),
right-tailed(<span class="math inline">\(&gt;\)</span>), or
two-tailed(<span class="math inline">\(\ne\)</span>).</p></li>
<li><p>Whenever zero is contained in the confidence interval of the
difference of the true means we conclude that there is no significant
difference between the two populations. <br></p></li>
</ul>
</div>
</div>
</div>
<div id="lesson-14" class="section level2 tabset tabset-pills">
<h2 class="tabset tabset-pills">Lesson 14</h2>
<div id="outcomes-5" class="section level3">
<h3>Outcomes</h3>
<ol style="list-style-type: decimal">
<li>Recognize when an Analysis of Variance (ANOVA) inferential procedure
is appropriate</li>
<li>Create numerical and graphical summaries of the data</li>
<li>Perform a hypothesis test for ANOVA using the following steps:
<ol style="list-style-type: lower-alpha">
<li>State the null and alternative hypotheses</li>
<li>Calculate the test-statistic, degrees of freedom and P-value of the
test using software</li>
<li>Assess statistical significance in order to state the appropriate
conclusion for the hypothesis test</li>
<li>Check the requirements for the hypothesis test</li>
</ol></li>
<li>State the properties of the F distribution</li>
</ol>
</div>
<div id="summary-5" class="section level3">
<h3>Summary</h3>
<div class="SummaryHeading">
Remember…
</div>
<div class="Summary">
<ul>
<li><p><strong>ANOVA</strong> is used to compare the means for several
groups. The hypotheses for the test are always: <span
class="math display">\[
\begin{align}
H_0: &amp; ~ \textrm{All the means are equal} \\
H_a: &amp; ~ \textrm{At least one of the means differs}
\end{align}
\]</span></p></li>
<li><p>For ANOVA testing we use an <strong><span
class="math inline">\(F\)</span>-distribution</strong>, which is
right-skewed. The <span class="math inline">\(P\)</span>-value of an
ANOVA test is always the area to the right of the <span
class="math inline">\(F\)</span>-statistic.</p></li>
<li><p>We can conduct ANOVA testing when the following three
requirements are satisfied:</p>
<ol style="list-style-type: decimal">
<li>The data come from a simple random sample.</li>
<li>The data are normally distributed within each group.
<ul>
<li>This is considered met unless one or more of the groups has a
<em>strongly</em> skewed distribution.</li>
</ul></li>
<li>The variance is constant.
<ul>
<li>This is satisfied when the largest variance is not more than four
times the smallest variance. <br></li>
</ul></li>
</ol></li>
</ul>
</div>
</div>
</div>
<div id="navigation" class="section level2">
<h2>Navigation</h2>
<center>
<table>
<colgroup>
<col width="38%" />
<col width="30%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Previous Reading</strong></th>
<th align="center"><strong>This Reading</strong></th>
<th align="center"><strong>Next Reading</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><a href="Lesson14.html">Lesson 14: <br> Inference for
Several Means (ANOVA)</a></td>
<td align="center">Lesson 15: <br> Review for Exam 2</td>
<td align="center"><a href="Lesson16.html">Lesson 16: <br> Describing
Categorical Data: Proportions; Sampling Distribution of a Sample
Proportion</a></td>
</tr>
</tbody>
</table>
</center>
</div>

<br />
<hr />
<p>Copyright &copy; 2020 Brigham Young University-Idaho. All rights reserved.</p>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
